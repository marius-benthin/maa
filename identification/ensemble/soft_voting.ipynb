{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble Soft Voting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Code\\\\maa\\\\')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from numpy import load, ndarray\n",
    "from sqlmodel import SQLModel, create_engine, Session, select\n",
    "\n",
    "from models.config import Config\n",
    "from models.models import Sample, EnsembleSample\n",
    "\n",
    "\n",
    "__author__ = \"Marius Benthin\"\n",
    "\n",
    "\n",
    "# load secrets from environment\n",
    "config = Config()\n",
    "\n",
    "# create database connection and tables\n",
    "sql_engine = create_engine(config.database_url)\n",
    "SQLModel.metadata.create_all(sql_engine)\n",
    "\n",
    "# load numpy feature vector\n",
    "\"\"\"\n",
    "with load(file='model_A_fnn_probabilities.npz', allow_pickle=True) as model_A:\n",
    "    p_model_A: ndarray = model_A['P']\n",
    "    x_model_A: list[int] = [sample_id for sample_id, _ in model_A['sample_ids']]\n",
    "\n",
    "with load(file='model_B_rfc_probabilities.npz', allow_pickle=True) as model_B:\n",
    "    p_model_B: ndarray = model_B['P']\n",
    "    x_model_B: list[int] = [sample_id for sample_id, _ in model_B['sample_ids']]\n",
    "\n",
    "with load(file='model_C_rfc_probabilities.npz', allow_pickle=True) as model_C:\n",
    "    p_model_C: ndarray = model_C['P']\n",
    "    x_model_C: list[int] = [sample_id for sample_id, _ in model_C['sample_ids']]\n",
    "\"\"\"\n",
    "with load(file='model_A_fnn_probabilities.npz', allow_pickle=True) as model_A:\n",
    "    p_model_A: ndarray = model_A['X']\n",
    "    x_model_A: list[int] = [sample_id for sample_id in model_A['sample_ids']]\n",
    "\n",
    "with load(file='model_B_rfc_probabilities.npz', allow_pickle=True) as model_B:\n",
    "    p_model_B: ndarray = model_B['X']\n",
    "    x_model_B: list[int] = [sample_id for sample_id in model_B['sample_ids']]\n",
    "\n",
    "with load(file='model_C_rfc_probabilities.npz', allow_pickle=True) as model_C:\n",
    "    p_model_C: ndarray = model_C['X']\n",
    "    x_model_C: list[int] = [sample_id for sample_id in model_C['sample_ids']]\n",
    "\n",
    "with Session(sql_engine) as session:\n",
    "    labels: List[str] = []\n",
    "    samples: Sample = session.exec(select(Sample).where(Sample.fold_id != None)).all()\n",
    "    parents: Dict[str, EnsembleSample] = {}\n",
    "    children: Dict[str, EnsembleSample] = {}\n",
    "    parent_model_A: bool = False\n",
    "    parent_model_B: bool = False\n",
    "    parent_model_C: bool = False\n",
    "    for sample in samples:\n",
    "        label: str = sample.group.name\n",
    "        fold_id: int = sample.fold_id\n",
    "        if len(sample.children) == 0:\n",
    "            if sample.id in x_model_A:\n",
    "                parent_model_A = True\n",
    "            if sample.id in x_model_B:\n",
    "                parent_model_B = True\n",
    "            if sample.id in x_model_C:\n",
    "                parent_model_C = True\n",
    "        else:\n",
    "            for child in sample.children:\n",
    "                if child.id in x_model_A:\n",
    "                    child_model_A = True\n",
    "                if child.id in x_model_B:\n",
    "                    child_model_B = True\n",
    "                if child.id in x_model_C:\n",
    "                    child_model_C = True\n",
    "                children[child.id] = EnsembleSample(\n",
    "                    fold_id=fold_id,\n",
    "                    label=label,\n",
    "                    model_A=child_model_A,\n",
    "                    model_B=child_model_B,\n",
    "                    model_C=child_model_C\n",
    "                )\n",
    "        parents[sample.id] = EnsembleSample(\n",
    "            fold_id=fold_id,\n",
    "            label=label,\n",
    "            model_A=parent_model_A,\n",
    "            model_B=parent_model_B,\n",
    "            model_C=parent_model_C\n",
    "        )\n",
    "\n",
    "        labels.append(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import sum, full, divide, argmax\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y = []\n",
    "y_cm = []\n",
    "y_pred = []\n",
    "y_pred_cm = []\n",
    "\n",
    "for parent_id, sample in parents.items():\n",
    "\n",
    "    predictions_model_1 = []\n",
    "    predictions_model_2 = []\n",
    "    predictions_model_3 = []\n",
    "\n",
    "    if sample.model_A and int(parent_id) in x_model_A:\n",
    "        predictions_model_1.append(p_model_A[x_model_A.index(int(parent_id))])\n",
    "    if sample.model_B and int(parent_id) in x_model_B:\n",
    "        predictions_model_2.append(p_model_B[x_model_B.index(int(parent_id))])\n",
    "    if sample.model_C and int(parent_id) in x_model_C:\n",
    "        predictions_model_3.append(p_model_C[x_model_C.index(int(parent_id))])\n",
    "\n",
    "    for child_id in sample.children:\n",
    "        if children[child_id].model_A and int(child_id) in x_model_A:\n",
    "            predictions_model_1.append(p_model_A[x_model_A.index(int(child_id))])\n",
    "        if children[child_id].model_B and int(child_id) in x_model_B:\n",
    "            predictions_model_2.append(p_model_B[x_model_B.index(int(child_id))])\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    if len(predictions_model_1) > 0:\n",
    "        predictions.append(divide(sum(predictions_model_1, axis=0), full((len(labels), 1), len(predictions_model_1))))\n",
    "\n",
    "    if len(predictions_model_2) > 0:\n",
    "        predictions.append(divide(sum(predictions_model_2, axis=0), full((len(labels), 1), len(predictions_model_2))))\n",
    "\n",
    "    if len(predictions_model_3) > 0:\n",
    "        predictions.append(divide(sum(predictions_model_3, axis=0), full((len(labels), 1), len(predictions_model_3))))\n",
    "\n",
    "    prediction = argmax(divide(sum(predictions, axis=0), full((len(labels), 1), len(predictions))))\n",
    "\n",
    "    y.append(sample.label)\n",
    "    if prediction is not None and prediction != -1:\n",
    "        y_cm.append(sample.label)\n",
    "        y_pred.append(labels[prediction])\n",
    "        y_pred_cm.append(labels[prediction])\n",
    "    else:\n",
    "        y_pred.append('unknown')\n",
    "\n",
    "print(classification_report(y_true=y, y_pred=y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(config.cm_size, config.cm_size))\n",
    "ConfusionMatrixDisplay.from_predictions(y_cm, y_pred_cm, xticks_rotation='vertical', ax=ax, normalize='true', values_format = '.2f')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
